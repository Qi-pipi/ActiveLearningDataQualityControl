{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a12e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "#unsupervised\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from tensorflow import keras\n",
    "\n",
    "#supervised\n",
    "import lightgbm as lgb\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "#al\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling,margin_sampling,entropy_sampling\n",
    "from modAL.disagreement import KL_max_disagreement\n",
    "from modAL.batch import uncertainty_batch_sampling\n",
    "\n",
    "#metric\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import matthews_corrcoef,cohen_kappa_score,balanced_accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cac34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=pd.read_csv('./randomtrain/6903102.csv')\n",
    "test_set=pd.read_csv('./randomtest/6903102.csv')\n",
    "print(len(train_set),len(test_set))\n",
    "\n",
    "x,y=train_set.shape\n",
    "#test set\n",
    "X_test=test_set.iloc[:,0:y-1]\n",
    "y_tru=test_set.iloc[:,y-1]\n",
    "print(len(X_test),len(y_tru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3deb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set1=train_set.iloc[:,:6]\n",
    "test_set1=test_set.iloc[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a92db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function use random grid search to find best parameters\n",
    "def getPar(model,dist,data,niter):\n",
    "    x,y=data.shape\n",
    "    clf = model\n",
    "    param_dist = dist\n",
    "    scoring = make_scorer(f1_score)\n",
    "    grid_search = GridSearchCV(clf, param_dist, cv=5, scoring=scoring)\n",
    "    grid_search.fit(data)\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best score:\", grid_search.best_score_)\n",
    "    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0369c332",
   "metadata": {},
   "source": [
    "# iforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000dab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest = IsolationForest(n_estimators=100, contamination='auto')\n",
    "params = {'n_estimators': [10, 50, 100],\n",
    "          'max_samples': [0.1, 0.5, 1.0],\n",
    "          'contamination': [0.01, 0.05, 0.1]}\n",
    "\n",
    "para=getPar(iforest,params,train_set1,10)\n",
    "\n",
    "\n",
    "iforest = IsolationForest(n_estimators=para['n_estimators'],max_samples=para['max_samples'],\n",
    "                                  contamination=para['contamination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute score\n",
    "iforest.fit(train_set1)\n",
    "if_scores = -iforest.score_samples(train_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine\n",
    "if_result = pd.concat([train_set,pd.Series(if_scores, name='score')], axis=1)\n",
    "\n",
    "# ascending by score\n",
    "if_data=if_result.sort_values(by='score', ascending=False)\n",
    "if_data.to_csv(\"if_score_low_top.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c735ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_if=if_data.iloc[:,:7]\n",
    "train_data_if"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb3290e",
   "metadata": {},
   "source": [
    "# autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac09cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(train_set1)\n",
    "\n",
    "#  Autoencoder model\n",
    "input_dim = scaled_data.shape[1]\n",
    "encoding_dim = 1\n",
    "hidden_dim = 2\n",
    "output_dim = input_dim\n",
    "input_layer = keras.layers.Input(shape=(input_dim,))\n",
    "encoder_layer1 = keras.layers.Dense(hidden_dim, activation='relu')(input_layer)\n",
    "encoder_layer2 = keras.layers.Dense(encoding_dim, activation='relu')(encoder_layer1)\n",
    "decoder_layer1 = keras.layers.Dense(hidden_dim, activation='relu')(encoder_layer2)\n",
    "decoder_layer2 = keras.layers.Dense(output_dim, activation=None)(decoder_layer1)\n",
    "autoencoder = keras.models.Model(inputs=input_layer, outputs=decoder_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and fit\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(train_set1, train_set1, epochs=50, batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute\n",
    "reconstructed_data = autoencoder.predict(train_set1)\n",
    "mse = np.mean(np.power(train_set1 - reconstructed_data, 2), axis=1)\n",
    "anomaly_scores = pd.Series(mse, name='anomaly_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine\n",
    "auto_result = pd.concat([train_set, anomaly_scores], axis=1)\n",
    "\n",
    "auto_data = auto_result.sort_values(by='anomaly_score', ascending=False)\n",
    "auto_data.to_csv(\"auto_score_low_top.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_auto=auto_data.iloc[:,:7]\n",
    "train_data_auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d432b83",
   "metadata": {},
   "source": [
    "# OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21658e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocsvm = OneClassSVM(kernel='rbf', nu=0.1)\n",
    "ocsvm.fit(train_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores3 = -ocsvm.decision_function(train_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0981402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine\n",
    "oc_result = pd.concat([train_set, pd.Series(scores3, name='score')], axis=1)\n",
    "\n",
    "oc_data=oc_result.sort_values(by='score', ascending=False)\n",
    "oc_data.to_csv(\"./other/oc_score_low_top.csv\")\n",
    "train_data_oc=oc_data.iloc[:,:7]\n",
    "train_data_oc\n",
    "\n",
    "\n",
    "# auto_data = auto_result.sort_values(by='anomaly_score', ascending=False)\n",
    "# train_data_auto=auto_data.iloc[:,:7]\n",
    "# train_data_auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b8ad6",
   "metadata": {},
   "source": [
    "# active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96399a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_initial= 100\n",
    "n_initial = 50\n",
    "N_QUERIES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bb39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pool\n",
    "def initial_data(n_initial,X_Pool,y_Pool):\n",
    "    #inital\n",
    "    #initial Labeled data\n",
    "    #X_initial, y_initial = X_train[], y_train[initial_idx]\n",
    "    X_L = X_Pool[:n_initial]\n",
    "    y_L = y_Pool[:n_initial]\n",
    "    # Unlabeled data\n",
    "    X_U = X_Pool[n_initial:]\n",
    "    y_U = y_Pool[n_initial:]\n",
    "    return X_L,y_L,X_U,y_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53171fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def al_learn(clf,sampling,X_initial,y_initial,X_re,y_re):\n",
    "    X_L = X_initial.copy()\n",
    "    y_L = y_initial.copy()\n",
    "    X_U,y_U =X_re.copy(),y_re.copy()\n",
    "    #print(len(X_U),len(y_U))\n",
    "    learner = al(clf,sampling,X_L,y_L)\n",
    "    y_pre=learner.predict(X_test)\n",
    "    unqueried_kappa=cohen_kappa_score(y_tru, y_pre)\n",
    "    unqueried_f1=f1_score(y_tru,y_pre)\n",
    "    #print(\"unqueried --------------------->\",unqueried_score)\n",
    "    kappa_history = [unqueried_kappa]\n",
    "    f1_history = [unqueried_f1]\n",
    "    \n",
    "    # Query\n",
    "    for index in range(N_QUERIES):\n",
    "        query_index=0\n",
    "        # Teach ActiveLearner model the record it has requested.\n",
    "        X, y = X_U[query_index].reshape(1, -1), y_U[query_index].reshape(1, )\n",
    "        #print(index+1,\"query label --------------------->\",y)\n",
    "        learner.teach(X=X, y=y)\n",
    "        \n",
    "        X_U, y_U = np.delete(X_U, query_index, axis=0), np.delete(y_U, query_index)\n",
    "        y_pre=learner.predict(X_test)\n",
    "        kappa=cohen_kappa_score(y_tru, y_pre)\n",
    "        f1=f1_score(y_tru,y_pre)\n",
    "        print(index+1,\"-------------------->\",kappa)\n",
    "        print(index+1,\"-------------------->\",f1)\n",
    "        # Recall precision F1\n",
    "        kappa_history.append(kappa)\n",
    "        f1_history.append(f1)\n",
    "    #print(len(X_U))\n",
    "    #draw(performance_history)\n",
    "    df_scores= pd.concat([pd.DataFrame(kappa_history,columns=['kappa']), \n",
    "                          pd.DataFrame(f1_history,columns=['f1'])],\n",
    "                         axis=1)\n",
    "    return df_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric\n",
    "def computeMetric(y_tru,y_pre):\n",
    "    acc = accuracy_score(y_tru,y_pre)\n",
    "    pre=precision_score(y_tru,y_pre)\n",
    "    recall=recall_score(y_tru,y_pre)\n",
    "    cm=confusion_matrix(y_tru,y_pre)\n",
    "    f1 = f1_score(y_tru,y_pre)\n",
    "    mcc=matthews_corrcoef(y_tru, y_pre)\n",
    "    kappa=cohen_kappa_score(y_tru, y_pre)\n",
    "    bac=balanced_accuracy_score(y_tru,y_pre)\n",
    "    print(\"acc:\",acc)\n",
    "    print(\"balanced acc:\",bac)\n",
    "    print(\"precision:\",pre)\n",
    "    print(\"recall:\",recall)\n",
    "    print(\"cm:\",cm)\n",
    "    print(\"f1:\",f1)\n",
    "    print(\"MCC:\", mcc)\n",
    "    print(\"Kappa:\",kappa)\n",
    "    \n",
    "    # confusion matrix\n",
    "#     cmap1 = sns.diverging_palette(260,-10,s=50, l=75, n=5, as_cmap=True)\n",
    "#     plt.subplots(figsize=(12,8))\n",
    "#     cf_matrix = confusion_matrix(y_tru, y_pre)\n",
    "#     sns.heatmap(cf_matrix/np.sum(cf_matrix), cmap = cmap1, annot = True, annot_kws = {'size':15})\n",
    "    \n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f79a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf4 catboost\n",
    "clf4 = CatBoostClassifier(loss_function='Logloss')\n",
    "clf4.fit(train_set1.values, train_set.iloc[:,6].values)\n",
    "y_pre=clf4.predict(X_test)\n",
    "computeMetric(y_tru,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def al(clf,strategy,X_L,y_L):\n",
    "    learner = ActiveLearner(estimator=clf,\n",
    "                            query_strategy=strategy,\n",
    "                            X_training=X_L, y_training=y_L)\n",
    "    return learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb26447",
   "metadata": {},
   "source": [
    "# auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03efeafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=train_set.shape\n",
    "\n",
    "\n",
    "#pool \n",
    "X_Pool = train_data_auto.iloc[:,0:y-1].values\n",
    "y_Pool = train_data_auto.iloc[:,y-1].values\n",
    "\n",
    "\n",
    "X_in_au,y_in_au,X_re_au,y_re_au=initial_data(n_initial,X_Pool,y_Pool)\n",
    "print(len(X_in_au),len(X_re_au))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling=uncertainty_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric1 = al_learn(clf4,sampling,X_in_au,y_in_au,X_re_au,y_re_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric1.rename(columns = {'kappa' : 'Auto_Kappa', 'f1' : 'Auto_F1'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c201d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62338931",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8.5, 10))\n",
    "x = np.linspace(1000, 2001, 1001)\n",
    "plt.plot(x,metric1)\n",
    "plt.legend(loc = \"best\")\n",
    "plt.title('Kappa of AL over Time')#Kappa F1\n",
    "plt.xlabel('Number of Queried Instance')\n",
    "plt.ylabel('Kappa')\n",
    "my_x_ticks = np.arange(1000, 2001, 50)\n",
    "plt.xticks(my_x_ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7951d",
   "metadata": {},
   "source": [
    "# iforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed87f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pool \n",
    "X_Pool = train_data_if.iloc[:,0:y-1].values\n",
    "y_Pool = train_data_if.iloc[:,y-1].values\n",
    "\n",
    "n_initial=300\n",
    "X_in_if,y_in_if,X_re_if,y_re_if=initial_data(n_initial,X_Pool,y_Pool)\n",
    "print(len(X_in_if),len(X_re_if))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7067c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric2 = al_learn(clf4,sampling,X_in_if,y_in_if,X_re_if,y_re_if)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8976522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric2.rename(columns = {'kappa' : 'IF_Kappa', 'f1' : 'IF_F1'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4888fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7869e07",
   "metadata": {},
   "source": [
    "# oneclasssvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af216ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pool \n",
    "X_Pool = train_data_oc.iloc[:,0:y-1].values\n",
    "y_Pool = train_data_oc.iloc[:,y-1].values\n",
    "\n",
    "\n",
    "X_in_oc,y_in_oc,X_re_oc,y_re_oc=initial_data(n_initial,X_Pool,y_Pool)\n",
    "print(len(X_in_oc),len(X_re_oc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric3 = al_learn(clf4,sampling,X_in_oc,y_in_oc,X_re_oc,y_re_oc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f19a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric3.rename(columns = {'kappa' : 'OCSVM_Kappa', 'f1' : 'OCSVM_F1'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4ddc94",
   "metadata": {},
   "source": [
    "# all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ccade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=pd.concat([metric1,metric2,metric3],axis=1)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a46699",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_csv(\"random_low_un_50_top.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac214214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0da80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al",
   "language": "python",
   "name": "al"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
