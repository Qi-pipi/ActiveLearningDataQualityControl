{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20728b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30afc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './dataset/'\n",
    "randomtrain_folder_path = \"./randomtrain/\"\n",
    "randomtest_folder_path = \"./randomtest/\"\n",
    "firsttrain_folder_path = \"./firsttrain/\"\n",
    "lasttest_folder_path = \"./lasttest/\"\n",
    "lastrandomtest_folder_path = \"./lastrandomtest/\"\n",
    "\n",
    "\n",
    "file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "\n",
    "if not os.path.exists(randomtrain_folder_path):\n",
    "    os.makedirs(randomtrain_folder_path)\n",
    "if not os.path.exists(randomtest_folder_path):\n",
    "    os.makedirs(randomtest_folder_path)\n",
    "if not os.path.exists(firsttrain_folder_path):\n",
    "    os.makedirs(firsttrain_folder_path)\n",
    "if not os.path.exists(lasttest_folder_path):\n",
    "    os.makedirs(lasttest_folder_path)\n",
    "if not os.path.exists(lastrandomtest_folder_path):\n",
    "    os.makedirs(lastrandomtest_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab0751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data and make sure the proportion in train and test set are equal\n",
    "def getRandomSplit(data, size):\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    split = StratifiedShuffleSplit(n_splits = 1,test_size = size,random_state = 42)\n",
    "\n",
    "    for train_index,test_index in split.split(data,data.iloc[:,-1]):\n",
    "        train_set = data.iloc[train_index,:]\n",
    "        test_set = data.iloc[test_index,:]\n",
    "\n",
    "    print(len(train_set),len(test_set))\n",
    "    return train_set,test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "867a967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the last 10% data \n",
    "\n",
    "# window\n",
    "def sliding_window(data, window_size,anomaly_ratio):\n",
    "    # from last raw\n",
    "    for i in range(len(data)-1, window_size-2, -10):\n",
    "        data_slice = data[i-window_size+1:i+1]\n",
    "        ratio = (data_slice[\"label\"] == 1).sum() / window_size*100\n",
    "        #print(ratio)\n",
    "        if anomaly_ratio*0.8 <= ratio <= anomaly_ratio*1.2:\n",
    "            #print(data_slice)\n",
    "            return data_slice\n",
    "\n",
    "\n",
    "def getLastSplit(data, size,anomaly_ratio):\n",
    "    data.sort_values(\"datetime\", ascending=True, inplace=True)\n",
    "    #print(data)\n",
    "    row,col=data.shape\n",
    "    window_size = int(size*row)\n",
    "    test_set = sliding_window(data, window_size,anomaly_ratio)\n",
    "    if test_set is None:\n",
    "        print(\"no test\")\n",
    "    time = test_set.iloc[0,0]\n",
    "    #print(time)\n",
    "    train_set = data[data['datetime'] < time]\n",
    "    print(len(train_set),len(test_set))\n",
    "    return train_set,test_set\n",
    "# windows keep the same rate of anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc3d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def compute ratio\n",
    "def comp_ratio(test_set1):\n",
    "    instance = test_set1[(test_set1['label']==1)]\n",
    "    rate=len(instance)/len(test_set1)*100\n",
    "    print(rate)\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c420d2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5903552_all.csv\n",
      "0.09260211955962548\n",
      "26241 2916\n",
      "18144 2915\n",
      "test2 length  2915\n",
      "0.102880658436214\n",
      "0.10291595197255575\n",
      "rate 0.16065917107583774\n",
      "15229 2915\n",
      "test22 length 2915\n",
      "0.0\n",
      "train1 length 15229\n",
      "6903248_all.csv\n",
      "0.04299636919549016\n",
      "56516 6280\n",
      "no test\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m anomaly_ratio\u001b[38;5;241m=\u001b[39mcomp_ratio(data)\n\u001b[1;32m      7\u001b[0m train_set1,test_set1 \u001b[38;5;241m=\u001b[39m getRandomSplit(data,\u001b[38;5;241m0.1\u001b[39m)\u001b[38;5;66;03m# random 90 10\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m train_set2,test_set2 \u001b[38;5;241m=\u001b[39m \u001b[43mgetLastSplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manomaly_ratio\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#last 10 and rest\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest2 length \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(test_set2))\n\u001b[1;32m     10\u001b[0m comp_ratio(test_set1)\n",
      "Cell \u001b[0;32mIn[34], line 24\u001b[0m, in \u001b[0;36mgetLastSplit\u001b[0;34m(data, size, anomaly_ratio)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno test\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#print(time)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m train_set \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m time]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(folder_path):\n",
    "    print(filename)\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        data = pd.read_csv(file_path)\n",
    "        anomaly_ratio=comp_ratio(data)\n",
    "        train_set1,test_set1 = getRandomSplit(data,0.1)# random 90 10\n",
    "        train_set2,test_set2 = getLastSplit(data,0.1, anomaly_ratio) #last 10 and rest\n",
    "        print(\"test2 length \",len(test_set2))\n",
    "        comp_ratio(test_set1)\n",
    "        comp_ratio(test_set2)\n",
    "        rate=len(test_set2)/len(train_set2)\n",
    "        print(\"rate\",rate)\n",
    "        train_set22,test_set22=getRandomSplit(train_set2, rate) #first \n",
    "        print(\"test22 length\", len(test_set22))\n",
    "        comp_ratio(test_set22)\n",
    "        #keep the same train size\n",
    "        train_set1 = train_set1.sample(n=len(train_set22))\n",
    "        print(\"train1 length\",len(train_set1))\n",
    "        #randomtrain_file_path = os.path.join(output_folder_path, f\"{filename}\")\n",
    "        #train_set1.to_csv(output_file_path, index=False)\n",
    "        #print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee53857f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251647\n",
      "0.2916784225522259\n",
      "176152 75495\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_set2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m train_set1,test_set1 \u001b[38;5;241m=\u001b[39m getRandomSplit(data,\u001b[38;5;241m0.3\u001b[39m)\u001b[38;5;66;03m# random 90 10\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#train_set2,test_set2 = getLastSplit(data,0.2, anomaly_ratio) #last 10 and rest\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest2 length \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(\u001b[43mtest_set2\u001b[49m))\n\u001b[1;32m      7\u001b[0m comp_ratio(test_set1)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#comp_ratio(test_set2)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#rate=len(test_set2)/len(train_set2)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#print(\"rate\",rate)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#keep the same train size\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#train_set1 = train_set1.sample(n=len(train_set2))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_set2' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/6903102_all.csv\")\n",
    "print(len(data))\n",
    "anomaly_ratio=comp_ratio(data)\n",
    "train_set1,test_set1 = getRandomSplit(data,0.3)# random 90 10\n",
    "#train_set2,test_set2 = getLastSplit(data,0.2, anomaly_ratio) #last 10 and rest\n",
    "print(\"test2 length \",len(test_set2))\n",
    "comp_ratio(test_set1)\n",
    "#comp_ratio(test_set2)\n",
    "#rate=len(test_set2)/len(train_set2)\n",
    "#print(\"rate\",rate)\n",
    "#train_set22,test_set22=getRandomSplit(train_set2, rate) \n",
    "#first \n",
    "#print(\"test22 length\", len(test_set22))\n",
    "#comp_ratio(test_set22)\n",
    "#keep the same train size\n",
    "#train_set1 = train_set1.sample(n=len(train_set2))\n",
    "print(\"train1 length\",len(train_set1))\n",
    "print(\"test1 length\",len(test_set1))\n",
    "# randomtrain_file_path = os.path.join(output_folder_path, f\"{filename}\")\n",
    "# train_set1.to_csv(output_file_path, index=False)\n",
    "# print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c5beb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set1.to_csv('./randomtrain/6903102.csv', index=False)\n",
    "train_set2.to_csv('./firsttrain/6903102.csv', index=False)\n",
    "\n",
    "test_set1.to_csv('./randomtest/6903102.csv', index=False)\n",
    "test_set2.to_csv('./lasttest/6903102.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ea2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5e9223f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251647\n",
      "0.2916784225522259\n",
      "176152 75495\n",
      "0.2914100271541162\n",
      "0.2917934511104046\n",
      "train1 length 176152\n",
      "test1 length 75495\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/6903102_all.csv\")\n",
    "print(len(data))\n",
    "anomaly_ratio=comp_ratio(data)\n",
    "train_set1,test_set1 = getRandomSplit(data,0.3)# random 7 3\n",
    "comp_ratio(test_set1)\n",
    "comp_ratio(train_set1)\n",
    "print(\"train1 length\",len(train_set1))\n",
    "print(\"test1 length\",len(test_set1))\n",
    "# randomtrain_file_path = os.path.join(output_folder_path, f\"{filename}\")\n",
    "# train_set1.to_csv(output_file_path, index=False)\n",
    "# print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77342e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set1.to_csv('./randomtrain/6903102.csv', index=False)\n",
    "test_set1.to_csv('./randomtest/6903102.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b49efb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53497\n",
      "29.364263416640185\n",
      "37447 16050\n",
      "29.364168024140785\n",
      "29.364485981308412\n",
      "train1 length 37447\n",
      "test1 length 16050\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./randomtest/3901890.csv\")\n",
    "print(len(data))\n",
    "anomaly_ratio=comp_ratio(data)\n",
    "test_set,validation_set = getRandomSplit(data,0.3)# random 7 3\n",
    "comp_ratio(test_set)\n",
    "comp_ratio(validation_set)\n",
    "print(\"test length\",len(test_set))\n",
    "print(\"validation length\",len(validation_set))\n",
    "# randomtrain_file_path = os.path.join(output_folder_path, f\"{filename}\")\n",
    "# train_set1.to_csv(output_file_path, index=False)\n",
    "# print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4bc1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_csv('./randomtest/3901890.csv', index=False)\n",
    "validation_set.to_csv('./valid/3901890.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127b58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b377b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e121b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e94a1612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63297\n",
      "0.16588463908242096\n",
      "44307 18990\n",
      "0.16850974196945762\n",
      "train1 length 44307\n",
      "test1 length 18990\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/3902110_all.csv\")\n",
    "print(len(data))\n",
    "anomaly_ratio=comp_ratio(data)\n",
    "train_set1,test_set1 = getRandomSplit(data,0.3)# random 7 3\n",
    "comp_ratio(test_set1)\n",
    "\n",
    "print(\"train1 length\",len(train_set1))\n",
    "print(\"test1 length\",len(test_set1))\n",
    "# randomtrain_file_path = os.path.join(output_folder_path, f\"{filename}\")\n",
    "# train_set1.to_csv(output_file_path, index=False)\n",
    "# print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f75ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set1.to_csv('./randomtrain/3902110.csv', index=False)\n",
    "test_set1.to_csv('./randomtest/3902110.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al",
   "language": "python",
   "name": "al"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
